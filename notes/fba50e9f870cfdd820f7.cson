type: "MARKDOWN_NOTE"
folder: "7671e01e5a4a4ee04aa9"
title: "2-hdfs 概念"
content: '''
  ### 2-hdfs 概念
  
  ---
  
  - ##### HDFS 设计基础与目标
  ```
  - 硬件错误是常态。因此需要冗余
  - 流式数据访问。即数据批量读取而非随即读写，Hadoop擅长做的是数据分析而不是事物处理
  - 大规模数据集
  - 简单一致性模型。 为了降低系统复杂度，对文件采用一次性写多次读的逻辑设计，
  即是文件一经写入，关闭，不能修改
  - 程序采用"数据就近"原则分配节点执行
  ```
  - ##### HDFS 体系结构
  ![image](http://ww1.sinaimg.cn/mw1024/e91aafadjw1f7z8l8f3t7j20go09eq3r.jpg)
  - **NameNode**
  ```
  - 管理文件系统的命名空间
  - 记录每个文件数据块在各个DataNode上的位置和副本信息
  - 协调客户端对文件的访问
  - 记录命名空间内的改动或空间本身属性的改动
  - NameNode 使用事物日志记录HDFS元数据的变化。使用映像文件存储文件系统的命名空间，包括文件映射，文件属性等。
  ```
  - **DataNode**
  ```
  - 负责在物理节点的存储管理
  - 一次写入，多次读取
  - 文件由数据块组成，典型的块大小64M
  - 数据块尽量散布到各个节点
  ```
  > **读取数据流程**
  
  ```
  - 客户端要访问HDFS中的一个文件
  - 首先从 NameNode 获得组成这个文件的数据块位置列表
  - 根据列表知道存储数据块的 DataNode
  - 访问datanode获取数据
  - NameNode 并不参与数据实际传输 
  ```
  
  - **事物日志**
  - **映像文件**
  - **SecondaryNameNode**
  
  - ##### HDFS 的可靠性:
  - **冗余副本策略**
  ```
  - 可以在 hdfs-site.xml中设置复制因子指定副本数量
  - 所有数据块都有副本
  - Datanode 启动时，遍历文件系统，产生一份 HDFS 数据块和本地文件对应关系列表（blockreport）汇报给NameNode;
  ```
  - **机架策略**
  ```
  - 集群一般放在不同的机架上， 机架见带宽要比机架内带宽要小
  - HDFS 的"机架感知"
  - 一般本机架存放一个副本，在其他机架在存放别的副本，这样可以防止机架失效时丢失数据，也可以提交带宽利用率。
  ```
  - **心跳机制**
  ```
  - Namenode 周期性从 Datanode 接受心跳信号和块报告
  - Namenode 根据块报告验证元数据
  - 没有按时发送心跳的 Datanode 会被标记为 宕机， 不会再给他任何I/O请求
  - 如果 Datanode 失效造成副本数量下降，并且低于预先设置的阈值， NameNode 会检测出这些数据块， 并在合适的时机进行重新复制
  - 引发复制还包括副本损坏， 磁盘错误, 复制因子被扩大
  ```
  - **安全模式**
  ```
  - NameNode 启动时会先经过一个"安全模式"阶段
  - 安全模式不会产生任何数据写
  - 在此阶段 Namenode 收集各个 Datanode 的报告， 当数据块达到最小副本数以上时被认为安全。
  - 在一定比例的数据块被确定为“安全”后， 在经过若干时间 ， 安全模式结束
  - 的那个检测到副本数不足的数据块时， 该块被复制直到达到最小副本数
  ```
  - **校验和**
  ```
  - 在文件创立时， 每个数据块都产生校验和
  - 校验和回作为单独一个隐藏文件保存在命名空间下
  - 客户端获取数据时可以检验校验和，从而确定数据块是否破坏
  - 如果数据块被破坏， 则读取其他副本
  ```
  - **回收站**
  ```
  - 删除文件时， 其实是放在回收站 /trash
  - 回收站里的文件可以快速恢复
  - 可以设置一个时间阈值， 当存放时间超过这个阈值时，就被彻底删除，并且释放占用的数据块
  ```
  - **元数据保护**
  ```
  - 映像文件和事务文件是 NameNode 的核心数据。 可以配置为多个副本
  - 副本会降低 Namenode 的处理速度, 但增加安全性
  - Namenode 依旧是单点， 如果发生故障要手工切换
  ```
  - **快照机制**
  ```
  支持存储某个时间点的映像， 需要时可以使数据重返这个时间的状态
  ```
  - #### HDFS 的高可用性:
  
  ![image](http://ww4.sinaimg.cn/mw1024/e91aafadjw1f8qo90vkw9j20fs09jdh3.jpg)
  
  ```
  Active NameNode 和 Standby NameNode：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，
  只有主 NameNode 才能对外提供读写服务。
  
  主备切换控制器 ZKFailoverController：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。
  ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换.
  当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。
  
  Zookeeper 集群：为主备切换控制器提供主备选举支持。
  
  共享存储系统：共享存储系统是实现 NameNode 的高可用最为关键的部分.
  共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和备用NameNode 通过共享存储系统实现元数据同步。
  在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。
  
  DataNode 节点：除了通过共享存储系统共享 HDFS 的元数据信息之外，主 NameNode 和备 NameNode 还需要共享 HDFS 的数据块和 DataNode 之间的映射关系。
  DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。
  
  每一个 namenode 运行着一个 轻量级的故障转移控制器, 其工作就是监视主 namenode 是否失效， 并在失效时进行切换.
  
  高可用实现了更进一步的优化， 以确保先前活动的namenode 不会执行危害系统并导致系统崩溃的操作- 规避
  系统引入了一些列规避机制， 包括杀死 namenode 进程， 收回访问共享存储目录的特权
  ```
  
  
'''
tags: []
isStarred: false
isTrashed: false
createdAt: "2017-09-20T10:13:31.902Z"
updatedAt: "2017-09-20T10:14:29.226Z"
