type: "MARKDOWN_NOTE"
folder: "7671e01e5a4a4ee04aa9"
title: "HDFS篇 (3) HDFS 架构"
content: '''
  ### HDFS篇 (3) HDFS 架构
  
  ---
  
  ### 元信息操作
  
  #### 1. 文件位置
  
  **dfs.name.dir**  : 属性指定目录的位置, 各个目录存储镜像的内容。
  **dfs.data.dir** : 数据文件目录位置
  **fs.checkpoint.dir**: secondsNamenode 数据文件位置
  
  #### 2. 文件系统客户端执行写操作时， 文件写操作首先被记录到编辑日志中。
  
  2.1 namenode 在内存中维护文件系统的元数据; 当编辑日志被修改时， 相关元数据也同步更新。
  2.2 每次执行写操作之后， 且在客户端发送成功代码之前， 编辑日志都需要更新和同步。
  2.3 fsimage 文件是文件系统元数据的一个永久检查点， 并非每一个些操纵都会更新该文件。
  2.4 如果 namenode 发生故障， 可以先把 fsimage 文件载入到内存重构新近的元数据， 在执行编辑日志中记录的各项操作.(事实上， namenode 在启动时正是这样做的)
  
  #### 3. **fsimage** 文件包括文件系统中的所有目录和文件 inode 的序列化信息。
  
  3.1 每个 inode 是一个文件或目录的元数据的内部描述方式。
  3.2 对于文件， 包含的信息有 "副本级别", 修改时间和访问时间，访问许可，块大小，组成一个文件的块等；
  3.3 对于目录来说， 包含的信息有修改时间， 访问许可， 和配额元数据等信息
  
  #### 4. **数据**存在于 datanode 中， 但 fsimage 文件并不描述 datanode .取而代之的是, namenode 将这种映射关系载入到内存中去.
  
  4.1 namenode 向 datanode 索取块列表以建立块的映射关系；
  4.2 namenode 还定期向 datanode 以确保它拥有最新的映射
  
  #### 5.运行 SecondsNamenode. 为namenode 内存中的文件系统元数据创建检查点
  
  5.1. secondsNamenode 请求主namenode 停止使用 edits文件, 暂时将新的写操作记录到一个新文件中。
  5.2. secondsNamenode 从 namenode 中获取 fsimage 和 edits 文件。
  5.3. secondsNamenode 将 fsimage 文件载入内存， 逐一执行 edits文件中的操作， 创建新的 fsimage 文件(消耗内存)
  5.4. secondsNamenode 将新的 fsimage 文件发送回 namenod 。
  5.5. namenode 从 secondsNamenode 接受 fsimage 文件替换旧的 fsimage 文件， 用步骤一产生的新的 edits 文件替换旧的 edits 文件。 同时还更新 fsimage 文件来记录检查点执行的信息.
  
  #### 6. 创建检查点的过程不仅为 namenode 创建检查点数据， 还使secondsnamenode 最终也有一份检查点数据.
  
  namenode 发生故障时, 可以从 secondsNamenode 中恢复数据：
  
  6.1. 将相关的存储目录复制到新的 namenode 中
  6.2. 使用 -importCheckpoint 启动 namenode 辅助进程， 从而将secondsNamenode 用作新的主 namenode
  
  > 借助该选项， 当 dfs.name.dir 属性定义的目录中没有元数据时， secondsNamenode 就从 fs.checkpoint.dir 目录中载入最新的检查点数据。
  
  #### 7. 关于 datanode 信息
  
  7.1. namespaceID 是 datanode 首次访问 namenode 的时候从 namenode 中获取获取的.
  7.2. 如果 dfs.data.dir 属性指定了不同磁盘上的多个目录， 那么数据块会以轮转的方式写到个各个磁盘目录上。
  
  #### 8. 安全模式
  
  8.1 namenode 启用时首先会将 fsimage 载入内存， 并执行 edits 中的各项操作。
  8.2 一旦在内存中成功建立文件系统元数据的映像， 则创建一个新的 fsimage 文件和一个空的编辑日志。
  8.3 之后 namenode 开始监听 RPC 和 http请求。 但是此刻 namenode 运行在安全模式
  
  
  在安全模式下， 只有那些访问文件系统元数据的文件系统操作是成功执行的。
  
  > 说明 :
  
  **系统中的数据块的位置并不是由 namenode 维护的， 而是以列表的形式存储在 datanode 中。**
  
  **在安全模式下， 各个datanode 会向namenode 中保存所有块位置的映射信息。**
  
  **当 namenode 了解到足够多的块信息时， 即可高效运行文件系统**
  
  **相关操作 :**
  1. 获取是否处于安全模式:
  ```
  hadoop dfsadmin -safemode get
  ```
  2. 进入安全模式:
  ```
  hadoop dfsadmin -safemode enter
  ```
  3. 退出安全模式
  ```
  hadoop dfsadmin -safemode leave
  ```
  
  ### 文件读写
  
  #### 1.文件写入过程
  
  1.1. 使用HDFS提供的客户端开发库Client，向远程的Namenode发起RPC请求；
  
  1.2. Namenode会检查要创建的文件是否已经存在，创建者是否有权限进行操作，成功则会为文件创建一个记录，否则会让客户端抛出异常；
  
  1.3. 当客户端开始写入文件的时候，开发库会将文件切分成多个packets，并在内部以数据队列"data queue"的形式管理这些packets，并向Namenode申请新的blocks，获取用来存储replicas的合适的datanodes列表，列表的大小根据在Namenode中对replication的设置而定。
  
  1.4. 开始以pipeline（管道）的形式将packet写入所有的replicas中。开发库把packet以流的方式写入第一个datanode，该datanode把该packet存储之后，再将其传递给在此pipeline中的下一个datanode，直到最后一个datanode，这种写数据的方式呈流水线的形式。
  
  1.5. 最后一个datanode成功存储之后会返回一个ack packet，在pipeline里传递至客户端，在客户端的开发库内部维护着"ack queue"，成功收到datanode返回的ack packet后会从"ack queue"移除相应的packet。
  
  1.6. 如果传输过程中，有某个datanode出现了故障，那么当前的pipeline会被关闭，出现故障的datanode会从当前的pipeline中移除，剩余的block会继续剩下的datanode中继续以pipeline的形式传输，同时Namenode会分配一个新的datanode，保持replicas设定的数量。
  
  
  #### 2.文件读取过程
  
  2.1. 使用HDFS提供的客户端开发库Client，向远程的Namenode发起RPC请求；
  
  2.2. Namenode会视情况返回文件的部分或者全部block列表，对于每个block，Namenode都会返回有该block拷贝的DataNode地址
  
  2.3. 客户端开发库Client会选取离客户端最接近的DataNode来读取block；如果客户端本身就是DataNode,那么将从本地直接获取数据.
  
  2.4. 读取完当前block的数据后，关闭与当前的DataNode连接，并为读取下一个block寻找最佳的DataNode；
  
  2.5. 当读完列表的block后，且文件读取还没有结束，客户端开发库会继续向Namenode获取下一批的block列表。
  
  6. 读取完一个block都会进行checksum验证，如果读取datanode时出现错误，客户端会通知Namenode，然后再从下一个拥有该block拷贝的datanode继续读。
  
  
  - #### 文件写入过程
  
  
  
'''
tags: []
isStarred: false
isTrashed: false
createdAt: "2017-09-20T10:14:32.593Z"
updatedAt: "2018-11-19T06:35:22.407Z"
