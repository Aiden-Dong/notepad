createdAt: "2018-12-21T07:53:33.333Z"
updatedAt: "2018-12-21T07:55:41.965Z"
type: "MARKDOWN_NOTE"
folder: "ef3e1850a2ffff04209d"
title: "Hive配置篇 (1) hive-site.xml"
content: '''
  ### Hive配置篇 (1) hive-site.xml
  
  ---
  
  ```
  <?xml version="1.0" encoding="UTF-8" standalone="no"?>
  <?xml-stylesheet type="text/xsl" href="configuration.xsl"?><!--
     Licensed to the Apache Software Foundation (ASF) under one or more
     contributor license agreements.  See the NOTICE file distributed with
     this work for additional information regarding copyright ownership.
     The ASF licenses this file to You under the Apache License, Version 2.0
     (the "License"); you may not use this file except in compliance with
     the License.  You may obtain a copy of the License at
  
         http://www.apache.org/licenses/LICENSE-2.0
  
     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
  --><configuration>
    <!-- WARNING!!! This file is auto generated for documentation purposes ONLY! -->
    <!-- WARNING!!! Any changes you make to this file will be ignored by Hive.   -->
    <!-- WARNING!!! You must make your changes in hive-site.xml instead.         -->
    <!-- Hive Execution Parameters -->
  
  
    <!-- security authenticate -->
    <property>
      <name>javax.jdo.option.ConnectionDriverName</name>
      <value>com.mysql.jdbc.Driver</value>
      <description>Driver class name for a JDBC metastore</description>
    </property>
  
    <property>
      <name>javax.jdo.option.ConnectionURL</name>
      <value>jdbc:mysql://XXX:3306/XXX?characterEncoding=UTF-8&amp;useSSL=true</value>
      <description>
        JDBC connect string for a JDBC metastore.
        To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.
        For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.
      </description>
    </property>
    
    <property>
      <name>javax.jdo.option.ConnectionUserName</name>
      <value>XXX</value>
      <description>Username to use against metastore database</description>
    </property>
  
    <property>
      <name>javax.jdo.option.ConnectionPassword</name>
      <value>XXX</value>
      <description>password to use against metastore database</description>
    </property>
  
  
    <property>
      <name>datanucleus.connectionPoolingType</name>
      <value>DBCP</value>
      <description>Uses a BoneCP connection pool for JDBC metastore</description>
    </property>
  
    <property>
      <name>datanucleus.connectionPool.testSQL</name>
      <value>select 1</value>
    </property>
  
    <property>
      <name>datanucleus.connectionPool.maxPoolSize</name>
      <value>4</value>
    </property>
  
    <property>
      <name>datanucleus.connectionPool.minIdle</name>
      <value>2</value>
    </property>
  
    <property>
      <name>javax.jdo.option.DetachAllOnCommit</name>
      <value>true</value>
      <description>Detaches all objects from session so that they can be used after transaction is committed</description>
    </property>
  
    <property>
      <name>javax.jdo.option.NonTransactionalRead</name>
      <value>true</value>
      <description>Reads outside of transactions</description>
    </property>
  
    <!-- tmp dir -->
    <property>
      <name>hive.exec.scratchdir</name>
      <value>/tmp/hive</value>
      <description>Scratch space for Hive jobs</description>
    </property>
  
    <property>
      <name>hive.exec.local.scratchdir</name>
      <value>/tmp/hive</value>
      <description>Local scratch space for Hive jobs</description>
    </property>
  
     <property>
       <name>hive.exec.stagingdir</name>
       <value>/tmp/hive-staging/.hive-staging</value>
     </property>
  
  
     <property>
       <name>hive.insert.into.multilevel.dirs</name>
       <value>true</value>
     </property>
  
    <!-- mapreduce -->
    <property>
     <name>mapred.max.split.size</name>
     <value>1073741824</value>
    </property>
  
    <property>
      <name>mapred.min.split.size.per.node</name>
      <value>1073741824</value>
    </property>
  
    <property>
      <name>mapred.min.split.size.per.rack</name>
      <value>1073741824</value>
    </property>
  
    <property>
      <name>hive.exec.reducers.bytes.per.reducer</name>
      <value>1073741824</value>
      <description>size per reducer.The default is 1G, i.e if the input size is 10G, it will use 10 reducers.</description>
    </property>
  
    <!-- acid -->
    <property>
      <name>hive.support.concurrency</name>
      <value>false</value>
      <description>
        Whether Hive supports concurrency control or not.
        A ZooKeeper instance must be up and running when using zookeeper Hive lock manager
      </description>
    </property>
  
    <property>
      <name>hive.enforce.bucketing</name>
      <value>false</value>
      <description>
        Whether Hive supports concurrency control or not.
        A ZooKeeper instance must be up and running when using zookeeper Hive lock manager
      </description>
    </property>
  
  
    <property>
      <name>hive.exec.dynamic.partition.mode</name>
      <value>strict</value>
      <description>
        In strict mode, the user must specify at least one static partition
        in case the user accidentally overwrites all partitions.
        In nonstrict mode all partitions are allowed to be dynamic.
      </description>
    </property>
  
  
     <property>
      <name>hive.txn.manager</name>
      <value>org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager</value>
      <description>
        Set to org.apache.hadoop.hive.ql.lockmgr.DbTxnManager as part of turning on Hive
        transactions, which also requires appropriate settings for hive.compactor.initiator.on,
        hive.compactor.worker.threads, hive.support.concurrency (true),
        and hive.exec.dynamic.partition.mode (nonstrict).
        The default DummyTxnManager replicates pre-Hive-0.13 behavior and provides
        no transactions.
      </description>
    </property>
  
    <property>
      <name>hive.compactor.initiator.on</name>
      <value>false</value>
      <description>
        Whether to run the initiator and cleaner threads on this metastore instance or not.
        Set this to true on one instance of the Thrift metastore service as part of turning
        on Hive transactions. For a complete list of parameters required for turning on
        transactions, see hive.txn.manager.
      </description>
    </property>
  
    <property>
      <name>hive.compactor.worker.threads</name>
      <value>0</value>
      <description>
        How many compactor worker threads to run on this metastore instance. Set this to a
        positive number on one or more instances of the Thrift metastore service as part of
        turning on Hive transactions. For a complete list of parameters required for turning
        on transactions, see hive.txn.manager.
        Worker threads spawn MapReduce jobs to do compactions. They do not do the compactions
        themselves. Increasing the number of worker threads will decrease the time it takes
        tables or partitions to be compacted once they are determined to need compaction.
        It will also increase the background load on the Hadoop cluster as more MapReduce jobs
        will be running in the background.
      </description>
    </property>
  
    <property>
      <name>hive.lock.sleep.between.retries</name>
      <value>60s</value>
      <description>
        Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
        The time should be in between 0 sec (exclusive) and 9223372036854775807 sec (exclusive).
        The maximum sleep time between various retries
      </description>
    </property>
  
  
    <!-- exec model -->
    <property>
      <name>hive.exec.submit.local.task.via.child</name>
      <value>false</value>
      <description>
        Determines whether local tasks (typically mapjoin hashtable generation phase) runs in
        separate JVM (true recommended) or not.
        Avoids the overhead of spawning new JVM, but can lead to out-of-memory issues.
      </description>
    </property>
  
   <property>
     <name>hive.exec.submitviachild</name>
     <value>true</value>
     <description/>
   </property>
  
   <property>
     <name>hive.mapred.mode</name>
     <value>strict</value>
     <description>Deprecated; use hive.strict.checks.* settings instead.</description>
   </property>
  
  
  
  
    <!-- datanucleus -->
  
    <property>
      <name>datanucleus.autoCreateSchema</name>
      <value>false</value>
    </property>
  
    <property>
      <name>datanucleus.fixedDatastore</name>
      <value>true</value>
    </property>
  
    <!-- hive keywords -->
    <property>
      <name>hive.support.sql11.reserved.keywords</name>
      <value>false</value>
    </property>
  
    <property>
      <name>hive.metastore.schema.verification</name>
      <value>false</value>
      <description>
        Enforce metastore schema version consistency.
        True: Verify that version information stored in is compatible with one from Hive jars.  Also disable automatic
              schema migration attempt. Users are required to manually migrate schema after Hive upgrade which ensures
              proper metastore schema migration. (Default)
        False: Warn if the version information stored in metastore doesn't match with one from in Hive jars.
      </description>
    </property>
  
  
   <!-- Mapreduce -->
  
    <property>
      <name>hive.execution.engine</name>
      <value>mr</value>
      <description>
        Expects one of [mr, tez, spark].
        Chooses execution engine. Options are: mr (Map reduce, default), tez, spark. While MR
        remains the default engine for historical reasons, it is itself a historical engine
        and is deprecated in Hive 2 line. It may be removed without further warning.
      </description>
    </property>
  
  
    <!-- s3 -->
    <property>
      <name>hive.blobstore.supported.schemes</name>
      <value>s3,s3a,s3n</value>
      <description>Comma-separated list of supported blobstore schemes.</description>
    </property>
  
    <!--optimize -->
    <property>
     <name>hive.optimize.index.filter</name>
     <value>true</value>
    </property>
  
    <property>
     <name>hive.optimize.index.groupby</name>
     <value>true</value>
    </property>
  
    <property>
     <name>hive.optimize.prunner</name>
     <value>true</value>
    </property>
  
  
    <property>
     <name>hive.limit.optimize.enable</name>
     <value>true</value>
    </property>
  
    <property>
     <name>hive.limit.row.max.size</name>
     <value>1000000</value>
    </property>
  
    <!-- show model -->
    <property>
      <name>hive.cli.print.header</name>
      <value>true</value>
      <description>Whether to print the names of the columns in query output.</description>
    </property>
  
  
    <!-- orc -->
    <property>
      <name>hive.exec.orc.default.stripe.size</name>
      <value>268435456</value>
      <description>
       Define the default ORC stripe size.
      </description>
    </property>
  
    <property>
      <name>hive.exec.orc.default.row.index.stride</name>
      <value>10000</value>
      <description>
        Define the default ORC index stride in number of rows.
      </description>
    </property>
  
    <property>
      <name>hive.exec.orc.default.buffer.size</name>
      <value>262144</value>
      <description>
        Define the default ORC buffer size in bytes.
      </description>
    </property>
  
    <property>
      <name>hive.exec.orc.default.block.padding</name>
      <value>true</value>
      <description>
        Define the default block padding.
      </description>
    </property>
  
    <property>
      <name>hive.exec.orc.default.compress</name>
      <value>ZLIB</value>
      <description>
        Define the default compression codec for ORC file.
      </description>
    </property>
  
    <property>
      <name>hive.exec.orc.dictionary.key.size.threshold</name>
      <value>0.8</value>
      <description>
        If the number of keys in a dictionary is greater than this fraction of the total number of
        non-null rows, turn off dictionary encoding.  Use 1 to always use dictionary encoding.
      </description>
    </property>
  
    <property>
      <name>hive.exec.orc.skip.corrupt.data</name>
      <value>false</value>
      <description>If ORC reader encounters corrupt data, this value will be used to determine
      whether to skip the corrupt data or throw exception. The default behavior is to throw exception.
      </description>
    </property>
  
    <!--
        ========================================================================================================================================
         finish configration
         =========================================================================================================================================
    -->
  </configuration>
  ```
'''
tags: []
isStarred: false
isTrashed: false
